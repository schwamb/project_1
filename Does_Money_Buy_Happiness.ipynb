{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_2015 = \"Resources/2015.csv\"\n",
    "happy_2016 = \"Resources/2016.csv\"\n",
    "happy_2017 = \"Resources/2017.csv\"\n",
    "happy_2018 = \"Resources/2018.csv\"\n",
    "happy_2019 = \"Resources/2019.csv\"\n",
    "\n",
    "happy_2015_df = pd.read_csv(happy_2015)\n",
    "happy_2016_df = pd.read_csv(happy_2015)\n",
    "happy_2017_df = pd.read_csv(happy_2015)\n",
    "happy_2018_df = pd.read_csv(happy_2015)\n",
    "happy_2019_df = pd.read_csv(happy_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN THE DATA\n",
    "\n",
    "#Create joins to merge file into single dataframe, with an added column for year\n",
    "\n",
    "for row in happy_2015:\n",
    "    happy_2015_df['Year'] = \"2015\"\n",
    "    happy_2016_df['Year'] = \"2016\"\n",
    "    happy_2017_df['Year'] = \"2017\"\n",
    "    happy_2018_df['Year'] = \"2018\"\n",
    "    happy_2019_df['Year'] = \"2019\"\n",
    "\n",
    "# Merge two dataframes using an outer join\n",
    "happy1516_df = pd.merge(happy_2015_df, happy_2016_df, how=\"outer\")\n",
    "happy151617_df = pd.merge(happy1516_df, happy_2017_df, how=\"outer\")\n",
    "happy15161718_df = pd.merge(happy151617_df, happy_2018_df, how=\"outer\")\n",
    "full_dataset_df = pd.merge(happy15161718_df, happy_2019_df, how=\"outer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEAN THE DATA: Aline, Susan\n",
    "\n",
    "#Inspect columns to see if row counts match up\n",
    "#Is object type pulling in as number? If not, change to numbers\n",
    "#Run a groupby for country to check for typos\n",
    "#Check for and handle NaN and null fields *as appropriate*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE DATAFRAMES: \n",
    "\n",
    "# DF Set 1: Meghan, Tom\n",
    "#Happiness score, country name, GDP -- calculate correlation coefficient and pull into df\n",
    "#Generosity, country name, GDP -- calculate correlation coefficient and pull into df\n",
    "\n",
    "# DF Set 2: James, Aline\n",
    "#Life expectancy, corruption, freedom\n",
    "#life expectancy, happiness, GDP -- chaos ensues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BINNING?\n",
    "\n",
    "#Happiness rank, top 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar graph/stacked bar graph of happiness percentage change over time?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
